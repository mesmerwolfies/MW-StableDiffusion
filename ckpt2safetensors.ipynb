{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üê∫ Convert Ckpt to Safetensors\n",
        "\n",
        "| | |\n",
        "|:--|:-:|\n",
        "| **SD WebUI** | [![Open in Colab](https://raw.githubusercontent.com/mesmerwolfies/MW-StableDiffusion/main/colab-badge.svg)](https://colab.research.google.com/github/mesmerwolfies/MW-StableDiffusion/blob/main/SDVN_WebUI_v3.ipynb)|\n",
        "| **Download Tools** | [![Open in Colab](https://raw.githubusercontent.com/mesmerwolfies/MW-StableDiffusion/main/colab-badge.svg)](https://colab.research.google.com/github/mesmerwolfies/MW-StableDiffusion/blob/main/SDVN_Download_tools.ipynb)|\n",
        "\n"
      ],
      "metadata": {
        "id": "sMD9zHwWG0zX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # ‚öôÔ∏è 1. Settings\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install torch safetensors -q\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from safetensors.torch import save_file\n",
        "import hashlib\n",
        "\n",
        "# --- H·∫±ng s·ªë ---\n",
        "CKPT_STR = \"ckpt\"\n",
        "SAFETENSORS_STR = \"safetensors\"\n",
        "HASH_START = 0x100000\n",
        "HASH_LENGTH = 0x10000\n",
        "\n",
        "# --- H√†m BƒÉm T·ªáp ---\n",
        "def get_file_hash(filename):\n",
        "    \"\"\"T√≠nh to√°n v√† tr·∫£ v·ªÅ m·ªôt ph·∫ßn hash SHA256 c·ªßa t·ªáp.\"\"\"\n",
        "    try:\n",
        "        with open(filename, \"rb\") as file:\n",
        "            m = hashlib.sha256()\n",
        "            file.seek(HASH_START)\n",
        "            m.update(file.read(HASH_LENGTH))\n",
        "            return m.hexdigest()[0:8]\n",
        "    except FileNotFoundError:\n",
        "        print(f\"C·∫¢NH B√ÅO: Kh√¥ng t√¨m th·∫•y t·ªáp ƒë·ªÉ bƒÉm: {filename}\")\n",
        "        return \"N/A\"\n",
        "    except Exception as e:\n",
        "        print(f\"C·∫¢NH B√ÅO: Kh√¥ng th·ªÉ bƒÉm t·ªáp {filename}: {e}\")\n",
        "        return \"L·ªói\"\n",
        "\n",
        "# --- H√†m T·∫£i Tr·ªçng s·ªë (cho .ckpt, lu√¥n t·∫£i l√™n CPU) ---\n",
        "def load_weights_from_ckpt(checkpoint_path):\n",
        "    \"\"\"T·∫£i tr·ªçng s·ªë t·ª´ t·ªáp .ckpt. Lu√¥n map v·ªÅ CPU.\"\"\"\n",
        "    try:\n",
        "        with torch.no_grad():\n",
        "            weights = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "            if \"state_dict\" in weights:\n",
        "                weights = weights[\"state_dict\"]\n",
        "                if \"state_dict\" in weights:\n",
        "                    weights.pop(\"state_dict\")\n",
        "            return weights\n",
        "    except FileNotFoundError:\n",
        "        print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y t·ªáp - {checkpoint_path}\")\n",
        "    except (RuntimeError, EOFError):\n",
        "        print(f\"L·ªñI: KH√îNG TH·ªÇ T·∫¢I CHECKPOINT: T·ªáp b·ªã h·ªèng - {checkpoint_path}\")\n",
        "    except (AttributeError, KeyError):\n",
        "        print(f\"L·ªñI: T·ªÜP KH√îNG ƒê∆Ø·ª¢C H·ªñ TR·ª¢ - {checkpoint_path}\")\n",
        "    except Exception as e:\n",
        "        print(f'L·ªói khi t·∫£i tr·ªçng s·ªë t·ª´ {checkpoint_path}: {e}')\n",
        "    return None\n",
        "\n",
        "# --- H√†m Chuy·ªÉn ƒë·ªïi T·ªáp ƒê∆°n ---\n",
        "def convert_single_ckpt_to_st_on_drive(input_ckpt_drive_path, output_safetensors_custom_name=None):\n",
        "    \"\"\"\n",
        "    Chuy·ªÉn ƒë·ªïi m·ªôt t·ªáp .ckpt t·ª´ Google Drive sang .safetensors v√† l∆∞u l·∫°i v√†o c√πng th∆∞ m·ª•c.\n",
        "    Args:\n",
        "        input_ckpt_drive_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn t·ªáp .ckpt ƒë·∫ßu v√†o tr√™n Google Drive.\n",
        "        output_safetensors_custom_name (str, optional):\n",
        "            - N·∫øu ƒë∆∞·ª£c cung c·∫•p (v√≠ d·ª•: \"my_model.safetensors\" ho·∫∑c \"my_model\"),\n",
        "              t√™n n√†y s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng cho t·ªáp ƒë·∫ßu ra (s·∫Ω t·ª± ƒë·ªông th√™m .safetensors n·∫øu thi·∫øu).\n",
        "            - N·∫øu None ho·∫∑c tr·ªëng, t√™n t·ªáp ƒë·∫ßu ra s·∫Ω gi·ªëng t√™n t·ªáp ƒë·∫ßu v√†o nh∆∞ng c√≥ ph·∫ßn m·ªü r·ªông .safetensors.\n",
        "    \"\"\"\n",
        "    print(f\"B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi t·ªáp ƒë∆°n: {input_ckpt_drive_path}\")\n",
        "    if not os.path.exists(input_ckpt_drive_path):\n",
        "        print(f\"L·ªñI: Kh√¥ng t√¨m th·∫•y t·ªáp ƒë·∫ßu v√†o: {input_ckpt_drive_path}\")\n",
        "        return False\n",
        "    if not input_ckpt_drive_path.lower().endswith(f\".{CKPT_STR}\"):\n",
        "        print(f\"L·ªñI: T·ªáp ƒë·∫ßu v√†o ph·∫£i c√≥ ph·∫ßn m·ªü r·ªông .{CKPT_STR}: {input_ckpt_drive_path}\")\n",
        "        return False\n",
        "\n",
        "    original_hash = get_file_hash(input_ckpt_drive_path)\n",
        "    print(f\"ƒêang t·∫£i tr·ªçng s·ªë t·ª´ {os.path.basename(input_ckpt_drive_path)} [{original_hash}] (l√™n CPU)...\" )\n",
        "    weights = load_weights_from_ckpt(input_ckpt_drive_path)\n",
        "    if weights is None:\n",
        "        print(f\"Kh√¥ng th·ªÉ t·∫£i tr·ªçng s·ªë cho {input_ckpt_drive_path}. B·ªè qua.\")\n",
        "        return False\n",
        "\n",
        "    input_dir = os.path.dirname(input_ckpt_drive_path)\n",
        "    input_filename_no_ext = os.path.splitext(os.path.basename(input_ckpt_drive_path))[0]\n",
        "    final_output_filename_no_ext = \"\"\n",
        "\n",
        "    if output_safetensors_custom_name and output_safetensors_custom_name.strip():\n",
        "        custom_name_stripped = output_safetensors_custom_name.strip()\n",
        "        # N·∫øu ng∆∞·ªùi d√πng nh·∫≠p c·∫£ ƒëu√¥i .safetensors, lo·∫°i b·ªè n√≥ ƒë·ªÉ chu·∫©n h√≥a\n",
        "        if custom_name_stripped.lower().endswith(f\".{SAFETENSORS_STR}\"):\n",
        "            final_output_filename_no_ext = os.path.splitext(custom_name_stripped)[0]\n",
        "        else:\n",
        "            final_output_filename_no_ext = custom_name_stripped\n",
        "    else:\n",
        "        final_output_filename_no_ext = input_filename_no_ext\n",
        "\n",
        "    final_output_path = os.path.join(input_dir, f\"{final_output_filename_no_ext}.{SAFETENSORS_STR}\")\n",
        "\n",
        "    print(f\"ƒêang c·ªë g·∫Øng l∆∞u t·ªáp ƒë√£ chuy·ªÉn ƒë·ªïi v√†o: {final_output_path}\")\n",
        "    try:\n",
        "        save_file(weights, final_output_path)\n",
        "        new_hash = get_file_hash(final_output_path)\n",
        "        print(f\"ƒê√£ chuy·ªÉn ƒë·ªïi th√†nh c√¥ng {os.path.basename(input_ckpt_drive_path)} [{original_hash}] sang {SAFETENSORS_STR}.\")\n",
        "        print(f\"ƒê√£ l∆∞u th√†nh {final_output_path} [{new_hash}].\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"L·ªñI: Kh√¥ng th·ªÉ l∆∞u t·ªáp .safetensors v√†o {final_output_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- H√†m Chuy·ªÉn ƒë·ªïi Th∆∞ m·ª•c ---\n",
        "def convert_folder_ckpt_to_st_on_drive(input_folder_drive_path):\n",
        "    \"\"\"\n",
        "    Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c t·ªáp .ckpt trong m·ªôt th∆∞ m·ª•c (v√† c√°c th∆∞ m·ª•c con c·ªßa n√≥) tr√™n Google Drive sang .safetensors.\n",
        "    C√°c t·ªáp ƒë√£ chuy·ªÉn ƒë·ªïi ƒë∆∞·ª£c l∆∞u trong c√πng th∆∞ m·ª•c v·ªõi t·ªáp .ckpt g·ªëc t∆∞∆°ng ·ª©ng.\n",
        "    \"\"\"\n",
        "    print(f\"--- B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi th∆∞ m·ª•c: {input_folder_drive_path} ---\")\n",
        "    if not os.path.isdir(input_folder_drive_path):\n",
        "        print(f\"L·ªñI: Th∆∞ m·ª•c ƒë·∫ßu v√†o kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng ph·∫£i l√† th∆∞ m·ª•c: {input_folder_drive_path}\")\n",
        "        return\n",
        "\n",
        "    ckpt_files_found = []\n",
        "    for root, _, files in os.walk(input_folder_drive_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(f\".{CKPT_STR}\"):\n",
        "                ckpt_files_found.append(os.path.join(root, file))\n",
        "\n",
        "    if not ckpt_files_found:\n",
        "        print(f\"Kh√¥ng t√¨m th·∫•y t·ªáp .{CKPT_STR} n√†o trong th∆∞ m·ª•c '{input_folder_drive_path}' (v√† c√°c th∆∞ m·ª•c con) ƒë·ªÉ chuy·ªÉn ƒë·ªïi.\")\n",
        "        print(\"--- K·∫øt th√∫c x·ª≠ l√Ω th∆∞ m·ª•c (kh√¥ng c√≥ t·ªáp) ---\")\n",
        "        return\n",
        "\n",
        "    print(f\"T√¨m th·∫•y {len(ckpt_files_found)} t·ªáp .{CKPT_STR} ƒë·ªÉ chuy·ªÉn ƒë·ªïi.\")\n",
        "    overall_success_count = 0\n",
        "    overall_failure_count = 0\n",
        "\n",
        "    for i, ckpt_file_path in enumerate(ckpt_files_found):\n",
        "        print(f\"\\nƒêang x·ª≠ l√Ω t·ªáp {i+1}/{len(ckpt_files_found)}: {ckpt_file_path}\")\n",
        "        # ƒê·ªëi v·ªõi chuy·ªÉn ƒë·ªïi th∆∞ m·ª•c, t√™n t·ªáp ƒë·∫ßu ra t√πy ch·ªânh kh√¥ng √°p d·ª•ng t·ª´ng t·ªáp,\n",
        "        # ch·ªâ c√≥ t√πy ch·ªçn th√™m h·∫≠u t·ªë.\n",
        "        # T√™n t·ªáp ƒë·∫ßu ra s·∫Ω d·ª±a tr√™n t√™n g·ªëc, l∆∞u c√πng v·ªã tr√≠.\n",
        "        input_dir_of_current_file = os.path.dirname(ckpt_file_path)\n",
        "        output_filename_base = os.path.splitext(os.path.basename(ckpt_file_path))[0]\n",
        "\n",
        "        # H√†m convert_single_ckpt_to_st_on_drive s·∫Ω t·ª± x·ª≠ l√Ω vi·ªác th√™m .safetensors\n",
        "        # v√† l∆∞u v√†o ƒë√∫ng th∆∞ m·ª•c (input_dir_of_current_file)\n",
        "        # Ch√∫ng ta truy·ªÅn output_filename_base l√†m t√™n t√πy ch·ªânh.\n",
        "        success = convert_single_ckpt_to_st_on_drive(ckpt_file_path, output_safetensors_custom_name=output_filename_base)\n",
        "        if success:\n",
        "            overall_success_count += 1\n",
        "        else:\n",
        "            overall_failure_count += 1\n",
        "\n",
        "    print(f\"\\n--- X·ª≠ l√Ω th∆∞ m·ª•c ho√†n t·∫•t ---\")\n",
        "    print(f\"T·ªïng c·ªông th√†nh c√¥ng: {overall_success_count} t·ªáp. Th·∫•t b·∫°i: {overall_failure_count} t·ªáp.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6HBpTu0CMjcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # üöÄ 2. Run\n",
        "\n",
        "#@markdown ### üìÅ Chuy·ªÉn ƒë·ªïi th∆∞ m·ª•c\n",
        "\n",
        "#@markdown T·∫•t c·∫£ c√°c t·ªáp `.ckpt` trong th∆∞ m·ª•c n√†y v√† c√°c th∆∞ m·ª•c con c·ªßa n√≥ s·∫Ω ƒë∆∞·ª£c chuy·ªÉn ƒë·ªïi.\n",
        "\n",
        "folder_on_drive = \"/content/drive/MyDrive/MesmerWolfies/MW-StableDiffusion/Model/ckpt\" #@param {type:\"string\"}\n",
        "convert_folder = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### üíΩ Chuy·ªÉn ƒë·ªïi t·ªáp ƒë∆°n l·∫ª\n",
        "\n",
        "ckpt_file_on_drive = \"/content/drive/MyDrive/MesmerWolfies/MW-StableDiffusion/Model/ckpt/\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Ch·ªâ t√™n t·ªáp. N·∫øu ƒë·ªÉ tr·ªëng, t√™n s·∫Ω gi·ªëng t·ªáp ƒë·∫ßu v√†o\n",
        "output_safetensors_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "input_folder_stripped = folder_on_drive.strip() if convert_folder else \"\"\n",
        "input_file_stripped = _ckpt_file_on_drive.strip()\n",
        "\n",
        "if input_folder_stripped: # ∆Øu ti√™n chuy·ªÉn ƒë·ªïi th∆∞ m·ª•c\n",
        "    print(\"∆Øu ti√™n: Chuy·ªÉn ƒë·ªïi th∆∞ m·ª•c\")\n",
        "    if not os.path.isdir(input_folder_stripped):\n",
        "        print(f\"L·ªñI (Th∆∞ m·ª•c): ƒê∆∞·ªùng d·∫´n ƒë·∫ßu v√†o kh√¥ng ph·∫£i l√† th∆∞ m·ª•c ho·∫∑c kh√¥ng t·ªìn t·∫°i: {input_folder_stripped}\")\n",
        "    else:\n",
        "        convert_folder_ckpt_to_st_on_drive(input_folder_stripped)\n",
        "elif input_file_stripped: # N·∫øu kh√¥ng c√≥ th∆∞ m·ª•c, th·ª≠ chuy·ªÉn ƒë·ªïi t·ªáp ƒë∆°n\n",
        "    print(\"Ch·∫ø ƒë·ªô: Chuy·ªÉn ƒë·ªïi t·ªáp ƒë∆°n l·∫ª\")\n",
        "    if not os.path.exists(input_file_stripped):\n",
        "        print(f\"L·ªñI (T·ªáp ƒë∆°n): Kh√¥ng t√¨m th·∫•y t·ªáp .ckpt ƒë·∫ßu v√†o t·∫°i: {input_file_stripped}\")\n",
        "    elif not input_file_stripped.lower().endswith(\".ckpt\"):\n",
        "        print(f\"L·ªñI (T·ªáp ƒë∆°n): T·ªáp ƒë·∫ßu v√†o ph·∫£i l√† t·ªáp .ckpt. ƒê∆∞·ªùng d·∫´n: {input_file_stripped}\")\n",
        "    else:\n",
        "        output_name = output_safetensors_name.strip() if output_safetensors_name.strip() else None\n",
        "        convert_single_ckpt_to_st_on_drive(input_file_stripped, output_name)\n",
        "else:\n",
        "    print(\"L·ªñI: Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n t·ªáp .ckpt HO·∫∂C ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ƒë·ªÉ chuy·ªÉn ƒë·ªïi.\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ASJ8b_M-OBMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}